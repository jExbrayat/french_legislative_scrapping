'logs.json' contains the status of execution for each commune.
It is used to rerun the scraping on webpages that failed.

'scraping_pipeline' is the main script for scraping the communes' web pages in 'communes_links.csv'.
It is thought to be executed from the project's root folder.